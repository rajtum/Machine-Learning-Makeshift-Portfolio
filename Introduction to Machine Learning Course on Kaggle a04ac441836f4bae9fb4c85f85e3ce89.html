<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Introduction to Machine Learning Course on Kaggle</title><style>
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}
.select-value-color-default { background-color: rgba(206,205,202,0.5); }
.select-value-color-gray { background-color: rgba(155,154,151, 0.4); }
.select-value-color-brown { background-color: rgba(140,46,0,0.2); }
.select-value-color-orange { background-color: rgba(245,93,0,0.2); }
.select-value-color-yellow { background-color: rgba(233,168,0,0.2); }
.select-value-color-green { background-color: rgba(0,135,107,0.2); }
.select-value-color-blue { background-color: rgba(0,120,223,0.2); }
.select-value-color-purple { background-color: rgba(103,36,222,0.2); }
.select-value-color-pink { background-color: rgba(221,0,129,0.2); }
.select-value-color-red { background-color: rgba(255,0,26,0.2); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="36bbedb0-ae9c-4671-930b-76a6ec3e6ba0" class="page sans"><header><h1 class="page-title">Introduction to Machine Learning Course on Kaggle</h1><table class="properties"><tbody><tr class="property-row property-row-created_time"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesCreatedAt"><path d="M6.98643729,14.0000972 C5.19579566,14.0000972 3.40419152,13.3106896 2.04245843,11.9323606 C-0.681017475,9.21200555 -0.680780251,4.76029539 2.04293482,2.04012507 C4.76664406,-0.68004331 9.22427509,-0.68004331 11.9480135,2.04013479 C13.272481,3.36277455 14,5.1330091 14,6.99552762 C14,8.87640182 13.2721894,10.6285043 11.9480135,11.9509302 C10.5679344,13.3105924 8.77756503,14.0000972 6.98643729,14.0000972 Z M10.2705296,7.00913883 L10.2705296,8.46099754 L10.2705296,8.65543362 L10.076181,8.65543362 L8.6543739,8.65543362 L5.72059514,8.65543362 L5.52619796,8.65543362 L5.52619796,8.46099754 L5.52619796,5.52541044 L5.52619796,3.37946773 L5.52619796,3.18502193 L5.72059514,3.18502193 L7.17253164,3.18502193 L7.36692883,3.18502193 L7.36692883,3.37946773 L7.36692883,6.81467358 L10.076181,6.81467358 L10.2705296,6.81467358 L10.2705296,7.00913883 Z M12.1601539,6.99552762 C12.1601539,5.61697497 11.6190112,4.32597154 10.6393933,3.34769528 C8.63253764,1.34336744 5.35197452,1.34061603 3.34153136,3.33944106 C3.33868273,3.34219247 3.33607716,3.34494388 3.33322852,3.34769528 C1.32397148,5.35459953 1.32372842,8.63641682 3.33322852,10.6433794 C5.34295224,12.6504489 8.62968901,12.6504489 10.6393933,10.6433794 C11.6190112,9.66506426 12.1601539,8.37408027 12.1601539,6.99552762 Z"></path></svg></span>Created Time</th><td><time>@Aug 14, 2020 10:58 AM</time></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesRelation"><polygon points="4.5 1 4.5 3 9.586 3 1 11.586 2.414 13 11 4.414 11 9.5 13 9.5 13 1"></polygon></svg></span>Cycles</th><td></td></tr><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M10.8889,5.5 L3.11111,5.5 L3.11111,7.05556 L10.8889,7.05556 L10.8889,5.5 Z M12.4444,1.05556 L11.6667,1.05556 L11.6667,0 L10.1111,0 L10.1111,1.05556 L3.88889,1.05556 L3.88889,0 L2.33333,0 L2.33333,1.05556 L1.55556,1.05556 C0.692222,1.05556 0.00777777,1.75556 0.00777777,2.61111 L0,12.5 C0,13.3556 0.692222,14 1.55556,14 L12.4444,14 C13.3,14 14,13.3556 14,12.5 L14,2.61111 C14,1.75556 13.3,1.05556 12.4444,1.05556 Z M12.4444,12.5 L1.55556,12.5 L1.55556,3.94444 L12.4444,3.94444 L12.4444,12.5 Z M8.55556,8.61111 L3.11111,8.61111 L3.11111,10.1667 L8.55556,10.1667 L8.55556,8.61111 Z"></path></svg></span>Deadline</th><td><time>@Aug 14, 2020</time></td></tr><tr class="property-row property-row-checkbox"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesCheckbox"><path d="M0,3 C0,1.34314 1.34326,0 3,0 L11,0 C12.6567,0 14,1.34314 14,3 L14,11 C14,12.6569 12.6567,14 11,14 L3,14 C1.34326,14 0,12.6569 0,11 L0,3 Z M3,1.5 C2.17139,1.5 1.5,2.17157 1.5,3 L1.5,11 C1.5,11.8284 2.17139,12.5 3,12.5 L11,12.5 C11.8286,12.5 12.5,11.8284 12.5,11 L12.5,3 C12.5,2.17157 11.8286,1.5 11,1.5 L3,1.5 Z M2.83252,6.8161 L3.39893,6.27399 L3.57617,6.10425 L3.92334,5.77216 L4.26904,6.10559 L4.44531,6.27582 L5.58398,7.37402 L9.28271,3.81073 L9.45996,3.64008 L9.80664,3.3056 L10.1538,3.63989 L10.3311,3.81067 L10.8936,4.35303 L11.0708,4.52399 L11.4434,4.88379 L11.0708,5.24353 L10.8936,5.41437 L6.1084,10.0291 L5.93115,10.2 L5.58398,10.5344 L5.23682,10.2 L5.05957,10.0292 L2.83057,7.87946 L2.65283,7.70801 L2.27832,7.34674 L2.6543,6.98694 L2.83252,6.8161 Z"></path></svg></span>Done</th><td><div class="checkbox checkbox-off"></div></td></tr><tr class="property-row property-row-select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesSelect"><path d="M7,13 C10.31348,13 13,10.31371 13,7 C13,3.68629 10.31348,1 7,1 C3.68652,1 1,3.68629 1,7 C1,10.31371 3.68652,13 7,13 Z M3.75098,5.32278 C3.64893,5.19142 3.74268,5 3.90869,5 L10.09131,5 C10.25732,5 10.35107,5.19142 10.24902,5.32278 L7.15771,9.29703 C7.07764,9.39998 6.92236,9.39998 6.84229,9.29703 L3.75098,5.32278 Z"></path></svg></span>Family</th><td></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesRelation"><polygon points="4.5 1 4.5 3 9.586 3 1 11.586 2.414 13 11 4.414 11 9.5 13 9.5 13 1"></polygon></svg></span>Goal</th><td><a href="https://www.notion.so/Become-a-Published-Researcher-530f1f72449540f5b97bcb0b02174a38"><span class="icon">🧪</span>Become a Published Researcher</a></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesRelation"><polygon points="4.5 1 4.5 3 9.586 3 1 11.586 2.414 13 11 4.414 11 9.5 13 9.5 13 1"></polygon></svg></span>Ideas</th><td><a href="https://www.notion.so/Kaggle-Python-ML-Course-Notes-e3904a3db654462d8ea75bbc40f7da76">Kaggle Python/ML Course Notes</a></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesRelation"><polygon points="4.5 1 4.5 3 9.586 3 1 11.586 2.414 13 11 4.414 11 9.5 13 9.5 13 1"></polygon></svg></span>Motifs</th><td><a href="https://www.notion.so/notes-ccaf130aaece46df84de2e937c35f590"><span class="icon">🗒️</span>#notes</a>, <a href="https://www.notion.so/cs-351676da17ba4751a6cbc5e6e9e00fa5"><span class="icon">👨‍💻</span>#cs</a></td></tr><tr class="property-row property-row-relation"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesRelation"><polygon points="4.5 1 4.5 3 9.586 3 1 11.586 2.414 13 11 4.414 11 9.5 13 9.5 13 1"></polygon></svg></span>Nibbles</th><td></td></tr><tr class="property-row property-row-select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesSelect"><path d="M7,13 C10.31348,13 13,10.31371 13,7 C13,3.68629 10.31348,1 7,1 C3.68652,1 1,3.68629 1,7 C1,10.31371 3.68652,13 7,13 Z M3.75098,5.32278 C3.64893,5.19142 3.74268,5 3.90869,5 L10.09131,5 C10.25732,5 10.35107,5.19142 10.24902,5.32278 L7.15771,9.29703 C7.07764,9.39998 6.92236,9.39998 6.84229,9.29703 L3.75098,5.32278 Z"></path></svg></span>Progress</th><td><span class="selected-value select-value-color-green">Completed</span></td></tr><tr class="property-row property-row-multi_select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesMultipleSelect"><path d="M4,3 C4,2.447715 4.447715,2 5,2 L12,2 C12.5523,2 13,2.447716 13,3 C13,3.55228 12.5523,4 12,4 L5,4 C4.447715,4 4,3.55228 4,3 Z M4,7 C4,6.447715 4.447715,6 5,6 L12,6 C12.5523,6 13,6.447716 13,7 C13,7.55228 12.5523,8 12,8 L5,8 C4.447715,8 4,7.55228 4,7 Z M4,11 C4,10.447715 4.447715,10 5,10 L12,10 C12.5523,10 13,10.447716 13,11 C13,11.55228 12.5523,12 12,12 L5,12 C4.447715,12 4,11.55228 4,11 Z M2,4 C1.44771525,4 1,3.55228475 1,3 C1,2.44771525 1.44771525,2 2,2 C2.55228475,2 3,2.44771525 3,3 C3,3.55228475 2.55228475,4 2,4 Z M2,8 C1.44771525,8 1,7.55228475 1,7 C1,6.44771525 1.44771525,6 2,6 C2.55228475,6 3,6.44771525 3,7 C3,7.55228475 2.55228475,8 2,8 Z M2,12 C1.44771525,12 1,11.5522847 1,11 C1,10.4477153 1.44771525,10 2,10 C2.55228475,10 3,10.4477153 3,11 C3,11.5522847 2.55228475,12 2,12 Z"></path></svg></span>Tags</th><td><span class="selected-value select-value-color-gray">#1</span></td></tr></tbody></table></header><div class="page-body"><nav id="2f8ff522-91e3-4364-9354-8fe82a722279" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#41e7598a-03cd-4a86-8854-a7aa55e2b279"><mark class="highlight-red">Selecting Data for Modeling</mark></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#1ce19524-26c1-4176-8efb-baefe7d4a9c0">Dot Notation for Prediction Target</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ad545a6c-7d89-4cf1-8c4e-cfe5856cbef2">Choosing &quot;Features&quot;</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#f20b2876-680b-4d5c-92be-8205699ff9a6">describe() and head()</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#b3eecfe4-6ffc-4c4e-a76b-b83d80efa408"><mark class="highlight-red">Building the Model</mark></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ba0acd89-dff9-4d4a-b46d-74675c53fb6f">Steps to Building a Model</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#9567a32f-c414-43a7-86ad-f3ddc157108e"><mark class="highlight-red">Model Validation</mark></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7f9bd2ee-5915-4ee2-a41f-2cfabb6e9f89">What is Model Validation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#03dd9075-1e75-4995-82af-182d130577f2">Predictive Accuracy Metric</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0a995a0d-e371-4591-99fd-b388aa1e8243">Splitting the Dataset</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#d9fad0a4-8fd6-484e-b844-2767ece546f9">Experimenting with Different Models (Underfitting vs. Overfitting)</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#877dc06f-4e42-4095-92d8-fc5fd316c15a">Random Forests</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#f5efedf2-cb4c-4777-99b9-0e643accb1c3"><mark class="highlight-red">Replacing Missing Values</mark></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#8b691b81-8128-4ca8-827b-1aeaffce019a">Option 1: Dropping All Values Across a Column</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#b67d3517-c34e-4229-ae0f-cb9f50fef564">Option 2: Imputation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#55e3d8a6-b33d-4dc8-bfc7-0f9428ff3aa5">Option 3: Remembered Imputation</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#6e3c95fb-00c5-4468-9d88-7a569b809a69"><mark class="highlight-red">Appendix A</mark></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#28a1d7e5-96d2-451d-abe8-e80befb55792">I. Models</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#97aa2ad4-4e60-4a67-be4d-fa61f0d27e5c"><code>Decision Tree</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#f6f2a707-69cd-46f8-ad1c-926321ffeb86"><code>Random Forest</code></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#2e7114e2-4e49-472a-8f44-3b755279cbf5">II. Data Processing</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#8e777f18-4efb-4866-8f7b-8a2a9def4ef7"><code>DataFrame.isnull().sum()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#2109d954-bbcb-4e84-916b-fdc34ae6ca04"><code>DataFrame.shape()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#4daa5f00-c42f-4db7-ab06-394654a440ba"><code>DataFrame.select_dtypes()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#4a927fa8-55d4-4b68-ad3a-625d9ca4768a"><code>DataFrame.dropna()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#0b01f3a2-2453-4bf6-b6d6-0026e8d7065c"><code>DataFrame.drop()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#1607c7b8-9cf7-46d5-825e-a764cf98cfff"><code>SimpleImputer()</code></a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#7ff7752b-376a-4bdb-886b-4adb0080deb1"><code>train_test_split(X, y, random_state = 0)</code></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#43dfbbef-628b-41f0-a00c-32f14c269af5">III. Predictive Accuracy Methods</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#d963fa14-3336-4373-ac1d-2a7b4195fb97"><code>Mean Absolute Error</code></a></div></nav><h1 id="41e7598a-03cd-4a86-8854-a7aa55e2b279" class=""><mark class="highlight-red">Selecting Data for Modeling</mark></h1><pre id="89bc8572-39ee-42c3-965d-8e7b4ebd36f3" class="code"><code>import pandas as pd

data = pd.read_csv(file_path)
data.columns

&gt;&gt;&gt; Index([&#x27;Column 1&#x27;,&#x27;Column 2&#x27;,&#x27;Column 3&#x27;])

if missing data values
data = data.dropna(axis=0)</code></pre><h3 id="1ce19524-26c1-4176-8efb-baefe7d4a9c0" class="">Dot Notation for Prediction Target</h3><p id="2e2883e9-c1c0-4481-92b6-166f96983c27" class="">You are able to take out a variable from a DataFrame through <strong><em>dot-notation. </em></strong>Single column stored in a <strong><em>series</em></strong>, a DataFrame with single column of data.</p><p id="0f09c29a-da1f-43bd-9317-c573e8e3040f" class="">By convention <strong><em>prediction target </em></strong>is called assigned the variable <strong>y</strong>:</p><pre id="6b3e3947-e28a-4a81-930f-773ed5cb271b" class="code"><code>y = data.AvgSleepingTimeForButter</code></pre><h3 id="ad545a6c-7d89-4cf1-8c4e-cfe5856cbef2" class="">Choosing &quot;Features&quot;</h3><p id="d4c53685-8f40-4b18-a946-bc4ed4151384" class="">Columns that are inputted into are model are called <em><strong>features</strong></em><em>. </em>We create an array with all the desired columns as strings and then assign it to variable <strong>x:</strong></p><pre id="b683a275-5827-4429-b524-f1011b3039ac" class="code"><code>key_features = [&#x27;Sleeping Frequency&#x27;,&#x27;Sleeping Duration&#x27;,&#x27;Sleep Quality&#x27;]
x = data[key_features]</code></pre><h3 id="f20b2876-680b-4d5c-92be-8205699ff9a6" class="">describe() and head()</h3><p id="33a6cd7d-8a1a-4e59-9835-d44b9cf03f47" class=""><code>describe()</code> - gives key statistical features like mean, count, sd, etc.</p><p id="5c01da44-1d37-4614-8edd-52b99ddf3fda" class=""><code>head()</code> - gives first five data rows</p><h1 id="b3eecfe4-6ffc-4c4e-a76b-b83d80efa408" class=""><mark class="highlight-red">Building the Model</mark></h1><p id="7dbfc9ac-c1d4-4e8c-80f9-669b66203a39" class="">Using scikit-learn to build models, library written as <strong><em>sklearn</em></strong></p><h3 id="ba0acd89-dff9-4d4a-b46d-74675c53fb6f" class="">Steps to Building a Model</h3><ol id="d27108ad-fdd2-4583-bc51-18d48b27dff5" class="numbered-list" start="1"><li><em>Define Model:</em> What type of model is it going to be? Neural Network? Decision Tree?</li></ol><ol id="151864f9-dbde-4b45-be88-723049596d4f" class="numbered-list" start="2"><li><em>Fit</em>: Captures the patterns in the data</li></ol><ol id="5fcd0770-dcc3-433d-9e07-c272a2563246" class="numbered-list" start="3"><li><em>Predict</em></li></ol><ol id="51d89ab3-7def-413f-acc3-520fec380462" class="numbered-list" start="4"><li><em>Evaluate</em></li></ol><pre id="f24c4c6b-613a-40bd-bd06-16857b3be2c1" class="code"><code>from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state=1)

model.fit(x,y)

#training dataset = x

## Specifying a number for the random_state ensures you get the same results

#prediction dataset = futurex

model.predict(futurex)</code></pre><h1 id="9567a32f-c414-43a7-86ad-f3ddc157108e" class=""><mark class="highlight-red">Model Validation</mark></h1><h3 id="7f9bd2ee-5915-4ee2-a41f-2cfabb6e9f89" class="">What is Model Validation</h3><p id="70d295b5-8499-4e87-95ab-08f4be442c78" class="">DON&#x27;T measure predicted with values on the same dataset trained, you want to see if the patterns your  model found extend beyond the training dataset.</p><h3 id="03dd9075-1e75-4995-82af-182d130577f2" class="">Predictive Accuracy Metric</h3><p id="e17e05a9-afda-4aae-a57a-4cd1b1a3f79b" class="">One measure of predictive accuracy is <strong><em>Mean Absolute Error</em></strong><strong>.</strong></p><pre id="add7a2b0-a4e0-4a75-a224-117e21aa9260" class="code"><code>from sklearn.metrics from mean_absolute_error
predicted_AvgSleepingTimeForButter = model.predict(futurex)

#y = actual_AvgSleepingTimeForButter
mean_absolute_error(predicted_AvgSleepingTimeForButter, y)</code></pre><h3 id="0a995a0d-e371-4591-99fd-b388aa1e8243" class="">Splitting the Dataset</h3><pre id="0ffeb5fc-f07b-4aa6-bb43-6bc64955d39e" class="code"><code>from sklearn.model_selection from train_test_split

train_X, train_Y, val_X, val_Y = train_test_split(X, y, random_state = 0)

#Create Model

model = DecisionTreeRegressor(random_state = 0)
model.fit(train_X, train_Y)

predicted_val_Y = model.predict(val_X)

mean_absolute_error(predicted_val_Y, val_Y)</code></pre><h3 id="d9fad0a4-8fd6-484e-b844-2767ece546f9" class="">Experimenting with Different Models (Underfitting vs. Overfitting)</h3><figure id="a04ac441-836f-4bae-9fb4-c85f85e3ce89" class="image"><a href="Introduction%20to%20Machine%20Learning%20Course%20on%20Kaggle%20a04ac441836f4bae9fb4c85f85e3ce89/OverUnderFitting.png"><img style="width:1192px" src="Introduction%20to%20Machine%20Learning%20Course%20on%20Kaggle%20a04ac441836f4bae9fb4c85f85e3ce89/OverUnderFitting.png"/></a></figure><ul id="84422736-ece9-4e3c-ae4d-e74bedc15803" class="toggle"><li><details open=""><summary>Full Code (WARNING: DIFFICULT TO READ)</summary><pre id="7e783f0e-62e9-4ab1-a05d-1cc3328467d9" class="code"><code>def minimize(candidate_max_leaf_nodes):
    get_MAE_values = {get_mae(candidate_max_leaf_nodes[i],train_X,val_X,train_y, val_y):candidate_max_leaf_nodes[i] for i in range(len(candidate_max_leaf_nodes))}
    best_tree_size = get_MAE_values[min(get_MAE_values.keys())]
    return best_tree_size

def minimizeMAE(candidate_max_leaf_nodes):
    get_MAE_values = {get_mae(candidate_max_leaf_nodes[i],train_X,val_X,train_y, val_y):candidate_max_leaf_nodes[i] for i in range(len(candidate_max_leaf_nodes))}
    a = min(get_MAE_values.keys())
    return a
def minimize_data(candidate_max_leaf_nodes):
    get_MAE_values = {candidate_max_leaf_nodes[i]:get_mae(candidate_max_leaf_nodes[i],train_X,val_X,train_y, val_y) for i in range(len(candidate_max_leaf_nodes))}
    array = []
    array = [item2 for item2 in get_MAE_values.values()]
    #[item for item in get_MAE_values.values()]
    return array
experiment = []
for i in range(200):
    experiment.append(i+2)

import matplotlib.pyplot as plt

minMaxLeafNode = minimize(experiment)
minMAE = minimizeMAE(experiment)

b = 0
b = minMaxLeafNode+2000
c = 0
c = int(minMAE-20)

plt.figure(figsize=(20,10))
plt.plot(experiment, minimize_data(experiment))
plt.plot(minMaxLeafNode, minMAE, &#x27;yo&#x27;)
plt.axis([0,200, 0,45000])
plt.text(10,40000,r&#x27;Underfitting&#x27;)
plt.text(150,35000,r&#x27;Overfitting&#x27;)
a = &#x27;Ideal Point: (Max Leaf Nodes = {}),(MAE = {:.10})&#x27;.format(minMaxLeafNode,minMAE)
plt.text(minMaxLeafNode,minMAE+2000,a)
plt.ylabel(r&#x27;MAE (in dollars)&#x27;)
plt.xlabel(&#x27;Max Leaf Nodes in Decision tree&#x27;)

plt.show()</code></pre></details></li></ul><h1 id="877dc06f-4e42-4095-92d8-fc5fd316c15a" class="block-color-red">Random Forests</h1><p id="82465d92-7324-42c1-b9f4-c2369c506313" class="">Even today&#x27;s most sophisticated machine learning techniques suffer from overfitting and underfitting, but many models have clever ideas which lead to better performance. </p><p id="7310136d-eb20-428b-9e69-8feb16d35ead" class="">In real life, trees make up forests.</p><p id="a0f1cb6f-4d4a-4b00-8da8-031b1501d874" class="">In coding world, decision trees make up random forests. Essentially, random forests predict the averaged value from all of its decision trees.</p><pre id="8e6965e0-6b09-4c34-841f-107699f388ac" class="code"><code>from sklearn.ensemble import RandomForestRegressor
from sylearn.metrics import mean_absolute_error

forest_model = RandomForestRegressor(random_state = 1)
forest_model.fit(train_X,train_y)

model_prediction = forest_model.predict(val_X)

mean_absolute_error(model_prediction,val_y)</code></pre><h1 id="f5efedf2-cb4c-4777-99b9-0e643accb1c3" class=""><mark class="highlight-red">Replacing Missing Values</mark></h1><h3 id="8b691b81-8128-4ca8-827b-1aeaffce019a" class="">Option 1: Dropping All Values Across a Column</h3><p id="7e35b6a4-8b91-4c1a-bcf9-8eff057ed8d6" class="">May lose potentially value from a column only because a few rows lack data.</p><figure id="bad3342f-3460-4922-96e1-adc52cae3b7e" class="image"><a href="https://i.imgur.com/Sax80za.png"><img style="width:1392px" src="https://i.imgur.com/Sax80za.png"/></a></figure><pre id="de827d62-8a82-4c13-92d4-8362366c4825" class="code"><code>#checking to see if there are any NaN values in any of the columns
columns_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]

X_train_opt_1 = X_train.drop(columns_with_missing, axis = 1)
X_valid_opt_2 = X_valid.drop(columns_with_missing, axis = 1)

#user-defined function
score_dataset(X_train_opt_1, X_valid_opt_2, y_train, y_valid)</code></pre><h3 id="b67d3517-c34e-4229-ae0f-cb9f50fef564" class="">Option 2: Imputation</h3><p id="56550ee4-7988-4c92-9b99-ce3cf6593ac7" class="">Placing values in the NaN based on the central tendencies of the column with the missing data.</p><figure id="e71f32fd-5256-47a9-9055-2d5d29d9c130" class="image"><a href="https://i.imgur.com/4BpnlPA.png"><img src="https://i.imgur.com/4BpnlPA.png"/></a></figure><pre id="d7921466-abb8-4026-a9fb-5a8c65c430af" class="code"><code>from sklearn.impute import SimpleImputer

my_inputer = SimpleInputer()

#inputting the data
X_train_opt_2 = pd.DataFrame(my_inputer.fit_transform(X_train))
X_valid_opt_2 = pd.DataFrame(my_inputer.transform(X_valid))

#inputting loses the columns, so place them back
X_train_opt_2.columns = X_train.columns
X_valid_opt_2.columns = X_valid.columns

#user-defined functions
score_dataset(X_train_opt_2, X_valid_opt_2, y_train, y_valid)</code></pre><h3 id="55e3d8a6-b33d-4dc8-bfc7-0f9428ff3aa5" class="">Option 3: Remembered Imputation</h3><p id="f7bccc43-a30e-4b81-a4c7-0b9448442de2" class="">Creates another column for each column with imputed values to state which values in that column were imputed and which ones are not.</p><figure id="31bbdc83-b6fb-468d-aa56-4a30c38f11e9" class="image"><a href="https://i.imgur.com/UWOyg4a.png"><img src="https://i.imgur.com/UWOyg4a.png"/></a></figure><pre id="7671225f-b1b4-4c89-b73f-5a0b611d4f44" class="code"><code>from sklearn.impute import SimpleImputer

X_train_rem = X_train.copy()
X_valid_rem = X_valid.copy()

my_imputer = SimpleImputer()

for col in columns_with_missing:
	X_train_rem[col + &#x27;_was_missing&#x27;] = X_train[col].isnull()
	x_valid_rem[col + &#x27;_was_missing&#x27;] = X_valid[col].isnull()

X_train_rem = pd.DataFrame(my_imputer.fit_transform(X_train_rem))
X_valid_rem = pd.DataFrame(my_imputer.transform(X_valid_rem))

X_train_rem.columns = X_train.columns
X_valid_rem.columns = X_valid.columns

score_dataset(X_train_rem, X_valid_rem, y_train, y_valid)</code></pre><h1 id="6e3c95fb-00c5-4468-9d88-7a569b809a69" class=""><mark class="highlight-red">Appendix A</mark></h1><h2 id="28a1d7e5-96d2-451d-abe8-e80befb55792" class="">I. Models</h2><h3 id="97aa2ad4-4e60-4a67-be4d-fa61f0d27e5c" class=""><code>Decision Tree</code></h3><p id="cb478f56-b6d0-442e-ad40-bde4c96489a2" class="">Identifies key features to separate and group data, and then predicts future data based on these <strong><em>leafs</em></strong><strong><strong>.</strong></strong></p><pre id="8737f765-9815-4c35-96bc-df02985a5289" class="code"><code>from sklearn.tree import DecisionTreeRegressor
decision_tree = DecisionTreeRegressor(max_leaf_nodes=10)

----
#max_leaf_nodes determines maximum number of leaves at end of decision tree (NOTE: cannot be 1 or None)</code></pre><h3 id="f6f2a707-69cd-46f8-ad1c-926321ffeb86" class=""><code>Random Forest</code></h3><p id="f82cf15f-f56b-44da-942e-39ba676f9892" class="">In real life, trees make up forests. </p><p id="6354072f-d53f-47fe-82e8-3628565b29f6" class="">In coding world, decision trees make up random forests. Essentially, random forests predict the averaged value from all of its decision trees.</p><pre id="5f86433d-dab9-4abc-9a26-20bd99d578c5" class="code"><code>from sklearn.ensemble import RandomForestRegressor
forest_model = RandomForestRegressor()</code></pre><p id="c2a16f5e-8e28-43be-9cac-28b1a30a7540" class="">
</p><h2 id="2e7114e2-4e49-472a-8f44-3b755279cbf5" class="">II. Data Processing</h2><h3 id="8e777f18-4efb-4866-8f7b-8a2a9def4ef7" class=""><code>DataFrame.isnull().sum()</code></h3><p id="927e4fba-7a21-45c8-bb11-2cf494c0bef7" class="">Returns an array on ints with the number of missing values in each column across the dataset</p><pre id="895d5ffd-97fc-4af0-ade9-814139cad902" class="code"><code>missing_vals_per_column = X_train.isnull().sum()

#Prints only columns with actual missing values (excludes the zeros)
print(missing_vals_per_column &gt; 0)</code></pre><h3 id="2109d954-bbcb-4e84-916b-fdc34ae6ca04" class=""><code>DataFrame.shape()</code></h3><p id="6e8c7f88-042d-41ad-8695-f64f30c8cea5" class="">Gives shape of dataset i.e. how many rows x columns</p><pre id="256efea5-ac8c-4fbd-b4e1-d9ecd15cc777" class="code"><code>X_train.shapes()
&gt;&gt;&gt; (3324,10)

#Means 3324 rows and 10 columns</code></pre><h3 id="4daa5f00-c42f-4db7-ab06-394654a440ba" class=""><code>DataFrame.select_dtypes()</code></h3><p id="140c1014-500c-4a6a-b2ef-cb3b862fbab1" class="">Select what types of data you would like</p><pre id="47ba5264-292c-42fc-bea8-57753a00ab99" class="code"><code># excludes any string / categorical variables with [&#x27;object&#x27;]
X = X_full.select_dtypes(exclude = [&#x27;object&#x27;])
X_test = X_test.select_dtypes(exlcude = [&#x27;object&#x27;])</code></pre><h3 id="4a927fa8-55d4-4b68-ad3a-625d9ca4768a" class=""><code>DataFrame.dropna()</code></h3><p id="9ec93faa-48a4-4c58-9c2c-738c8ec86f29" class="">Removes rows without target values </p><pre id="528de08f-35ae-42e5-af17-e1baaa4acdf8" class="code"><code>import pandas as pd

#Axis = 0 says focus on on dropping rows (compare with axis = 1, which drops columns)
#Subset says drop rows with NaN in this column or columns
#InPlace says do you want to return a value or not, if this is True, I will perform change on data without returning anything

X_full.dropna(axis = 0, subset = [&#x27;SalePrice&#x27;], inplace = True)</code></pre><h3 id="0b01f3a2-2453-4bf6-b6d6-0026e8d7065c" class=""><code>DataFrame.drop()</code></h3><p id="6421938b-f50e-410e-8fe9-b9c0b5416998" class="">Removes specified rows</p><pre id="3adef56f-5061-4967-83c9-9635d329a272" class="code"><code>import pandas as pd

#Ideally before DataFrame.drop() you would do this:
y = X_full.SalePrice

#[&#x27;SalePrice&#x27;] is specified column, axis = 1 means remove column(s), inplace will return nothing
X_full.drop([&#x27;SalePrice&#x27;], axis = 1, inplace = True)</code></pre><h3 id="1607c7b8-9cf7-46d5-825e-a764cf98cfff" class=""><code>SimpleImputer()</code></h3><p id="453c9e17-8408-4e21-858c-2bb76cd4d00d" class="">Inputs educated guesses for the NaN in the data</p><pre id="57104b3d-83b8-463a-8f1f-2366a30c53b4" class="code"><code>import pandas as pd
from sklearn.impute import SimpleImputer()
my_imputer = SimpleImputer()

#fits the imputer based on X_train and imputes values to imputed_X_train
imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))
imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid)

#remember to add back the columns
imputed_X_train.columns = X_train.columns
imputed_X_valid.columns = X_valid.columns</code></pre><h3 id="7ff7752b-376a-4bdb-886b-4adb0080deb1" class=""><code>train_test_split(X, y, random_state = 0)</code></h3><p id="77e52022-5413-478a-91a8-2670f65e4200" class="">Creates a training and validation data set from the whole dataset. Make sure <code>random_state = 0</code> because that controls how the data is split.</p><pre id="094b8eb4-984e-4a5b-9e97-8322896bd49b" class="code"><code>from sklearn.model_selection import train_test_split

X = keyFeaturesArray
y = predictionArray

train_X, train_y, val_X, val_y = train_test_split(X, y, random_state = 0)</code></pre><h2 id="43dfbbef-628b-41f0-a00c-32f14c269af5" class="">III. Predictive Accuracy Methods</h2><h3 id="d963fa14-3336-4373-ac1d-2a7b4195fb97" class=""><code>Mean Absolute Error</code></h3><p id="ee6d1af7-067b-4f8e-9acd-2806ef6f2d80" class="">Checks how far from the actual value the model&#x27;s predicted value is.</p><pre id="35e0e434-c02d-4f08-9d03-9837ce3c757f" class="code"><code>from skylearn.metrics import mean_absolute_error

mean_absolute_error(pred_val, val_y)</code></pre><p id="c1ac6932-ab21-43ab-8305-ee78d8344867" class="">
</p></div></article></body></html>